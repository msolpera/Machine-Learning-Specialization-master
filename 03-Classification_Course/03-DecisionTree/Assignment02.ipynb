{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing binary decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the lending club dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv', low_memory=False)\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop(columns='bad_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='safe_loans'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loans['safe_loans'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to count number of mistakes while predicting majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0    \n",
    "    # Count the number of 1's (safe loans)\n",
    "    safe_loans = len(labels_in_node[labels_in_node==1])\n",
    "    # Count the number of -1's (risky loans)\n",
    "    risky_loans = len(labels_in_node[labels_in_node==-1])        \n",
    "    # Return the number of mistakes that the majority classifier makes.\n",
    "    return np.min([safe_loans, risky_loans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n",
      "Test passed!\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test case 1\n",
    "\n",
    "example_labels = np.array([-1, -1, 1, 1, 1])\n",
    "\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 1 failed... try again!')\n",
    "\n",
    "# Test case 2\n",
    "example_labels = np.array([-1, -1, 1, 1, 1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 3 failed... try again!')\n",
    "    \n",
    "# Test case 3\n",
    "example_labels = np.array([-1, -1, -1, -1, -1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 3 failed... try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables categóricas identificadas: ['grade', 'term', 'home_ownership', 'emp_length']\n"
     ]
    }
   ],
   "source": [
    "categorical_variables = loans.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Variables categóricas identificadas: {categorical_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None)\n",
    "loans_encoded_data = encoder.fit_transform(loans[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener los nombres de las nuevas columnas\n",
    "feature_names = []\n",
    "for i, feature in enumerate(categorical_variables):\n",
    "    feature_vals = encoder.categories_[i]\n",
    "    for val in feature_vals:\n",
    "        feature_names.append(f\"{feature}_{val}\")\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las variables codificadas\n",
    "loans_encoded_df = pd.DataFrame(loans_encoded_data, columns=feature_names)\n",
    "\n",
    "# Eliminar las columnas categóricas originales y agregar las nuevas columnas codificadas\n",
    "loans_numeric_data = loans.drop(columns=categorical_variables)\n",
    "\n",
    "loans_encoded_df.index=loans_numeric_data.index\n",
    "loans_enc_data = pd.concat([loans_numeric_data, loans_encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = pd.read_json('module-5-assignment-2-train-idx.json')\n",
    "test_idx = pd.read_json('module-5-assignment-2-test-idx.json')\n",
    "train_data = loans_enc_data.iloc[train_idx[0].values]\n",
    "test_data = loans_enc_data.iloc[test_idx[0].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "      <th>emp_length_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122572</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122575</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122588</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122599</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122603</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37224 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  \\\n",
       "1               -1      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "6               -1      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "7               -1      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "10              -1      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "12              -1      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "...            ...      ...      ...      ...      ...      ...      ...   \n",
       "122572           1      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "122575           1      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "122588           1      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "122599           1      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "122603           1      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "\n",
       "        grade_G  term_ 36 months  term_ 60 months  ...  emp_length_2 years  \\\n",
       "1           0.0              0.0              1.0  ...                 0.0   \n",
       "6           0.0              0.0              1.0  ...                 0.0   \n",
       "7           0.0              0.0              1.0  ...                 0.0   \n",
       "10          0.0              1.0              0.0  ...                 0.0   \n",
       "12          0.0              1.0              0.0  ...                 0.0   \n",
       "...         ...              ...              ...  ...                 ...   \n",
       "122572      0.0              1.0              0.0  ...                 0.0   \n",
       "122575      0.0              1.0              0.0  ...                 0.0   \n",
       "122588      0.0              1.0              0.0  ...                 0.0   \n",
       "122599      1.0              0.0              1.0  ...                 0.0   \n",
       "122603      0.0              1.0              0.0  ...                 0.0   \n",
       "\n",
       "        emp_length_3 years  emp_length_4 years  emp_length_5 years  \\\n",
       "1                      0.0                 0.0                 0.0   \n",
       "6                      0.0                 1.0                 0.0   \n",
       "7                      0.0                 0.0                 0.0   \n",
       "10                     0.0                 0.0                 0.0   \n",
       "12                     1.0                 0.0                 0.0   \n",
       "...                    ...                 ...                 ...   \n",
       "122572                 0.0                 0.0                 0.0   \n",
       "122575                 0.0                 0.0                 1.0   \n",
       "122588                 1.0                 0.0                 0.0   \n",
       "122599                 0.0                 0.0                 0.0   \n",
       "122603                 0.0                 0.0                 0.0   \n",
       "\n",
       "        emp_length_6 years  emp_length_7 years  emp_length_8 years  \\\n",
       "1                      0.0                 0.0                 0.0   \n",
       "6                      0.0                 0.0                 0.0   \n",
       "7                      0.0                 0.0                 0.0   \n",
       "10                     0.0                 0.0                 0.0   \n",
       "12                     0.0                 0.0                 0.0   \n",
       "...                    ...                 ...                 ...   \n",
       "122572                 0.0                 0.0                 0.0   \n",
       "122575                 0.0                 0.0                 0.0   \n",
       "122588                 0.0                 0.0                 0.0   \n",
       "122599                 0.0                 0.0                 0.0   \n",
       "122603                 0.0                 0.0                 0.0   \n",
       "\n",
       "        emp_length_9 years  emp_length_< 1 year  emp_length_nan  \n",
       "1                      0.0                  1.0             0.0  \n",
       "6                      0.0                  0.0             0.0  \n",
       "7                      0.0                  1.0             0.0  \n",
       "10                     0.0                  1.0             0.0  \n",
       "12                     0.0                  0.0             0.0  \n",
       "...                    ...                  ...             ...  \n",
       "122572                 0.0                  1.0             0.0  \n",
       "122575                 0.0                  0.0             0.0  \n",
       "122588                 0.0                  0.0             0.0  \n",
       "122599                 0.0                  0.0             0.0  \n",
       "122603                 0.0                  0.0             0.0  \n",
       "\n",
       "[37224 rows x 26 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of grade_A loans : 6422.0\n",
      "Expexted answer               : 6422\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of grade_A loans : %s\" % str(train_data['grade_A'].sum()+test_data['grade_A'].sum()))\n",
    "print(\"Expexted answer               : 6422\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to pick best feature to split on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "\n",
    "    best_feature = None # Keep track of the best feature \n",
    "    best_error = 10     # Keep track of the best error so far \n",
    "    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n",
    "\n",
    "    # Convert to float to make sure error gets computed correctly.\n",
    "    num_data_points = float(len(data))  \n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        left_split = data[data[feature] == 0]\n",
    "        \n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        right_split =  data[data[feature] == 1]\n",
    "            \n",
    "        # Calculate the number of misclassified examples in the left split.\n",
    "        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n",
    "        left_mistakes = intermediate_node_num_mistakes(left_split[target])\n",
    "\n",
    "        # Calculate the number of misclassified examples in the right split.\n",
    "        right_mistakes = intermediate_node_num_mistakes(right_split[target])\n",
    "            \n",
    "        # Compute the classification error of this split.\n",
    "        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n",
    "        error = (left_mistakes + right_mistakes)/num_data_points\n",
    "\n",
    "        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "        \n",
    "    \n",
    "    return best_feature # Return the best feature we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "if best_splitting_feature(train_data, feature_names, 'safe_loans') == 'term_ 36 months':\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test failed... try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values):    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True}   ## YOUR CODE HERE \n",
    "   \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len(target_values[target_values == 1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])    \n",
    "\n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = 1\n",
    "    else:\n",
    "        leaf['prediction'] = -1\n",
    "\n",
    "    # Return the leaf node\n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth = 0, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    target_values = data[target]\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "\n",
    "    # Stopping condition 1\n",
    "    # (Check if there are mistakes at current node.\n",
    "    # Recall you wrote a function intermediate_node_num_mistakes to compute this.)\n",
    "    if  intermediate_node_num_mistakes(target_values)== 0:  \n",
    "        print(\"Stopping condition 1 reached.\")     \n",
    "        # If not mistakes at current node, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2 (check if there are remaining features to consider splitting on)\n",
    "    if remaining_features == []:   \n",
    "        print(\"Stopping condition 2 reached.\")   \n",
    "        # If there are no remaining features to consider, make current node a leaf node\n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth >= max_depth:  \n",
    "        print(\"Reached maximum depth. Stopping for now.\")\n",
    "        # If the max tree depth has been reached, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "\n",
    "    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n",
    "    splitting_feature = best_splitting_feature(data, remaining_features, target)\n",
    "\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print(\"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target])\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(right_split[target])\n",
    "\n",
    "        \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, current_depth + 1, max_depth)        \n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, current_depth + 1, max_depth)        \n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade_A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade_B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length_nan. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade_D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade_E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade_A. (4701, 0)\n",
      "Creating leaf node.\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "small_data_decision_tree = decision_tree_create(train_data, feature_names, 'safe_loans', max_depth = 3)\n",
    "if count_nodes(small_data_decision_tree) == 13:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test failed... try again!')\n",
    "    print('Number of nodes found                :', count_nodes(small_data_decision_tree))\n",
    "    print('Number of nodes that should be there : 13' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade_A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade_B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade_C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade_D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade_E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade_E. (2058, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade_D. (2190, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length_5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade_C. (969, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade_C. (34, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade_C. (45, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length_nan. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length_< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade_B. (85, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade_B. (11, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade_B. (5, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade_D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade_E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade_F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length_nan. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade_G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade_A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length_8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade_A. (347, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership_OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade_A. (1276, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade_A. (4701, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree = decision_tree_create(train_data, feature_names, target, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions with a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):\n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate:\n",
    "             print(\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction']\n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate:\n",
    "             print(\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if (split_feature_value == 0).values:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24    True\n",
      "Name: grade_A, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0:1]['grade_A']==0)\n",
    "#print('Predicted class: %s ' % classify(my_decision_tree, test_data[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    }
   ],
   "source": [
    "if (test_data[0:1]['grade_A']==0).values:   \n",
    "    print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  \\\n",
      "24          -1      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
      "\n",
      "    term_ 36 months  term_ 60 months  ...  emp_length_2 years  \\\n",
      "24              0.0              1.0  ...                 1.0   \n",
      "\n",
      "    emp_length_3 years  emp_length_4 years  emp_length_5 years  \\\n",
      "24                 0.0                 0.0                 0.0   \n",
      "\n",
      "    emp_length_6 years  emp_length_7 years  emp_length_8 years  \\\n",
      "24                 0.0                 0.0                 0.0   \n",
      "\n",
      "    emp_length_9 years  emp_length_< 1 year  emp_length_nan  \n",
      "24                 0.0                  0.0             0.0  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "Predicted class: -1 \n"
     ]
    }
   ],
   "source": [
    "print(test_data[0:1])\n",
    "print('Predicted class: %s ' % classify(my_decision_tree, test_data[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term_ 36 months = 24    0.0\n",
      "Name: term_ 36 months, dtype: float64\n",
      "Split on grade_A = 24    0.0\n",
      "Name: grade_A, dtype: float64\n",
      "Split on grade_B = 24    0.0\n",
      "Name: grade_B, dtype: float64\n",
      "Split on grade_C = 24    0.0\n",
      "Name: grade_C, dtype: float64\n",
      "Split on grade_D = 24    1.0\n",
      "Name: grade_D, dtype: float64\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree, test_data[0:1], annotate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data, target):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction = [classify(tree, data[i:i+1]) for i in range(len(data))]\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error and return it\n",
    "    no_mistakes = abs(prediction + data[target])/2\n",
    "    num_mistakes = len(data) - no_mistakes.sum()\n",
    "    return float(num_mistakes)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3837785437311504"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree, test_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stump(tree, name = 'root'):\n",
    "    split_name = tree['splitting_feature'] # split_name is something like 'term. 36 months'\n",
    "    if split_name is None:\n",
    "        print(\"(leaf, label: %s)\" % tree['prediction'])\n",
    "        return None\n",
    "    split_feature, split_value = split_name.split('_')\n",
    "    print('                       %s' % name)\n",
    "    print('         |---------------|----------------|')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('  [{0} == 0]               [{0} == 1]    '.format(split_name))\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('    (%s)                         (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [term_ 36 months == 0]               [term_ 36 months == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       term_ 36 months\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade_A == 0]               [grade_A == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left'], my_decision_tree['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       grade_A\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade_B == 0]               [grade_B == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left']['left'], my_decision_tree['left']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       term_ 36 months\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade_D == 0]               [grade_D == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['right'], my_decision_tree['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       grade_A\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade_E == 0]               [grade_E == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['right']['left'], my_decision_tree['left']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
